import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from streamlit_option_menu import option_menu
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
import time
import os

# Streamlit configuration
st.set_page_config(page_title="Labubu Trend Analysis", layout="wide")

# Sidebar Navigation
with st.sidebar:
    selected = option_menu(
        "Menu",
        ["Crawl D·ªØ Li·ªáu", "D·ª± ƒêo√°n Xu H∆∞·ªõng"],
        icons=["cloud-download", "bar-chart"],
        menu_icon="cast",
        default_index=0,
    )

# Function to crawl data from Shopee using Selenium
def crawl_shopee(keyword="labubu", max_pages=1):
    options = Options()
    options.add_argument("--headless")  # Run in headless mode (no UI)
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    service = Service("/path/to/chromedriver")  # Update with the path to ChromeDriver

    driver = webdriver.Chrome(service=service, options=options)
    product_data = []

    try:
        for page in range(max_pages):
            url = f"https://shopee.vn/search?keyword={keyword}&page={page}"
            driver.get(url)
            time.sleep(5)  # Wait for the page to load

            # Locate product items
            items = driver.find_elements(By.CLASS_NAME, "shopee-search-item-result__item")
            for item in items:
                try:
                    title = item.find_element(By.CLASS_NAME, "_1NoI8_._16BAGk").text
                    sales = item.find_element(By.CLASS_NAME, "_18SLBt").text if item.find_elements(By.CLASS_NAME, "_18SLBt") else "0"
                    product_data.append({"Product": title, "Sales": sales})
                except Exception as e:
                    continue
    finally:
        driver.quit()
    
    return pd.DataFrame(product_data)

# Mock function for social media data (fallback)
def crawl_social_media(keyword="labubu", max_posts=50):
    return pd.DataFrame({
        "Post": ["Labubu is amazing!", "Best gift for kids!", "Limited Labubu stocks!"],
        "Likes": [150, 230, 300],
        "Comments": [20, 35, 50]
    })

# Page 1: Crawl Data
if selected == "Crawl D·ªØ Li·ªáu":
    st.title("üõí Crawl D·ªØ Li·ªáu T·ª´ Shopee & MXH")

    # Shopee Crawl
    st.subheader("üîó Crawl t·ª´ Shopee")
    keyword = st.text_input("Nh·∫≠p t·ª´ kh√≥a t√¨m ki·∫øm (v√≠ d·ª•: labubu):", value="labubu")
    max_pages = st.slider("S·ªë trang c·∫ßn crawl:", 1, 5, 1)

    if st.button("Crawl Shopee"):
        try:
            shopee_data = crawl_shopee(keyword, max_pages)
            if not shopee_data.empty:
                st.write(f"K·∫øt qu·∫£ crawl t·ª´ Shopee ({len(shopee_data)} s·∫£n ph·∫©m):")
                st.dataframe(shopee_data)
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu n√†o t·ª´ Shopee.")
        except Exception as e:
            st.error(f"C√≥ l·ªói x·∫£y ra: {e}")

    # Social Media Crawl
    st.subheader("üí¨ Crawl t·ª´ M·∫°ng X√£ H·ªôi")
    if st.button("Crawl M·∫°ng X√£ H·ªôi"):
        try:
            social_data = crawl_social_media(keyword=keyword, max_posts=50)
            st.write(f"K·∫øt qu·∫£ crawl t·ª´ m·∫°ng x√£ h·ªôi ({len(social_data)} b√†i ƒëƒÉng):")
            st.dataframe(social_data)
        except Exception as e:
            st.error(f"C√≥ l·ªói x·∫£y ra: {e}")

# Page 2: D·ª± ƒêo√°n Xu H∆∞·ªõng
if selected == "D·ª± ƒêo√°n Xu H∆∞·ªõng":
    st.title("üìà D·ª± ƒêo√°n Xu H∆∞·ªõng S·∫£n Ph·∫©m: Labubu Doll")

    # Sample dataset
    data = {
        "Date": ["2024-12-01", "2024-12-02", "2024-12-03", "2024-12-04", "2024-12-05"],
        "Sales": [150, 180, 170, 200, 210],  # L∆∞·ª£t b√°n
        "Posts": [10, 15, 12, 18, 20],       # S·ªë b√†i ƒëƒÉng
        "Interactions": [2000, 2500, 2200, 3000, 3500]  # L∆∞·ª£t t∆∞∆°ng t√°c
    }
    df = pd.DataFrame(data)
    df["Date"] = pd.to_datetime(df["Date"])
    df["Day"] = (df["Date"] - df["Date"].min()).dt.days

    # Display dataset
    st.subheader("üîç D·ªØ Li·ªáu M·∫´u")
    st.dataframe(df)

    # Plot trends
    st.subheader("üìä Bi·ªÉu ƒê·ªì Xu H∆∞·ªõng Hi·ªán T·∫°i")
    plt.figure(figsize=(10, 6))
    plt.plot(df["Date"], df["Sales"], marker='o', label="Sales (TMƒêT)")
    plt.plot(df["Date"], df["Posts"], marker='o', label="Posts (MXH)")
    plt.plot(df["Date"], df["Interactions"], marker='o', label="Interactions (MXH)")
    plt.title("Xu H∆∞·ªõng S·∫£n Ph·∫©m: Labubu Doll")
    plt.xlabel("Date")
    plt.ylabel("Counts")
    plt.legend()
    plt.grid()
    st.pyplot(plt)

    # Prediction with Linear Regression
    X = df[["Day"]].values
    y_sales = df["Sales"].values
    model_sales = LinearRegression()
    model_sales.fit(X, y_sales)
    future_days = np.array([[i] for i in range(6, 11)])
    sales_predictions = model_sales.predict(future_days)

    # Display predictions
    future_dates = pd.date_range(df["Date"].iloc[-1] + pd.Timedelta(days=1), periods=5)
    predicted_data = pd.DataFrame({
        "Date": future_dates,
        "Predicted Sales": sales_predictions.astype(int)
    })

    st.subheader("üìÖ D·ª± ƒêo√°n Doanh S·ªë Trong 5 Ng√†y Ti·∫øp Theo")
    st.dataframe(predicted_data)

    # Plot predictions
    st.subheader("üîÆ Bi·ªÉu ƒê·ªì D·ª± ƒêo√°n Doanh S·ªë")
    plt.figure(figsize=(10, 6))
    plt.plot(df["Date"], df["Sales"], marker='o', label="Actual Sales")
    plt.plot(future_dates, sales_predictions, marker='o', linestyle="--", label="Predicted Sales")
    plt.title("D·ª± ƒêo√°n Doanh S·ªë: Labubu Doll")
    plt.xlabel("Date")
    plt.ylabel("Sales")
    plt.legend()
    plt.grid()
    st.pyplot(plt)
